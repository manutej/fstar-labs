# MARS: Epistemic Dimension Playbook

**Dimension**: What's knowable vs hidden, what assumptions underlie thinking
**Agent**: MARS
**Usage**: Reference during assumption surfacing and knowledge gap analysis

---

## Core Question
"What do we know, what don't we know, and what are we assuming without realizing?"

---

## The Epistemic Lens

### What MARS Looks For
- **Hidden problems**: What specialists can't see (systems perspective reveals)
- **Invisible assumptions**: What's taken for granted
- **Constraint classification**: Hard vs soft vs self-imposed
- **Knowledge gaps**: What we need to understand but don't
- **Paradigm blindness**: What's invisible from current worldview
- **Information asymmetries**: Who knows what, and what gets hidden

---

## Visible vs Hidden Problems

### The Visibility Spectrum

**Easily Visible** (Everyone sees):
```
- Old machines (can see with eyes)
- Slow processes (can measure)
- High costs (can calculate)
- Low customer satisfaction (can survey)
```

**Harder to See** (Specialists might notice):
```
- Bottlenecks (need process analysis)
- Skill gaps (need assessment)
- Technology constraints (need technical review)
- Budget pressures (need financial analysis)
```

**Nearly Invisible** (Systems lens reveals):
```
- Organizational trauma (previous failed initiatives)
- Learned helplessness (people have given up)
- Broken trust (management and workers)
- Fear of change (from past experiences)
- Dysfunctional feedback loops (self-reinforcing problems)
- Culture misalignment (what's actually valued vs stated)
```

**Completely Hidden** (Usually remains invisible):
```
- Unconscious assumptions ("this is just how it is")
- Invisible power structures (who really decides)
- Unstated conflicts (what no one talks about)
- Paradigm limitations (what we can't even imagine)
```

### Why Systems Lens Reveals Hidden

**Specialist View**: "How can I do my job better?"
→ Sees domain-specific problems
→ Misses system-wide patterns

**Systems View**: "How do parts work together?"
→ Sees patterns across domains
→ Reveals where system breaks down
→ Shows invisible factors specialists miss

### MARS Method: Make Hidden Visible

1. **Ask about contradictions**
   - "Why does everyone know the process is broken, but nothing changes?"
   - → Reveals: Fear, politics, learned helplessness

2. **Listen to complaints**
   - What do people say about problems?
   - What do they say differently in private?
   - → Gap reveals where truth is hidden

3. **Trace failures**
   - When something failed before, why?
   - What was blamed, what was real cause?
   - → Reveals: Pattern of avoidance, scapegoating

4. **Watch behavior**
   - What do people actually do vs what they say?
   - What are they protecting?
   - → Reveals: True priorities, real concerns

---

## Constraint Classification

### Three Types of Constraints

**HARD CONSTRAINTS** (Cannot change):
```
- Laws of physics (gravity, entropy)
- Legal/regulatory requirements
- Contractual obligations (can't change without cost)
- Natural resource limits
- Market realities (can't force demand)

Approach: Accept and design around
```

**SOFT CONSTRAINTS** (Expensive/difficult to change):
```
- Budget limitations (can raise more, but costs)
- Timeline pressures (can extend, but costs)
- Staff availability (can hire, but costs)
- Technology investments (can upgrade, but costs)
- Organizational culture (can shift, but takes time)

Approach: Negotiate where high ROI
```

**SELF-IMPOSED CONSTRAINTS** (Assumed to be hard, but changeable):
```
- "We've always done it this way"
- "Our customers won't accept that"
- "That's not possible in our industry"
- "We're too small/big to do this"
- "That would never work here"

Approach: Challenge and test assumptions
```

### The Constraint Relaxation Strategy

1. **Identify all mentioned constraints**
   List everything blocking the work

2. **Classify each constraint**
   Hard, soft, or self-imposed?

3. **Challenge self-imposed constraints**
   - Is this actually true, or assumed?
   - What would change if we dropped this assumption?
   - Has anyone tested this?

4. **Negotiate soft constraints where high ROI**
   - If we could change this, what becomes possible?
   - Is the benefit worth the cost of change?
   - Can we phase the change to spread cost?

5. **Accept hard constraints, design around them**
   - These are immovable
   - Creativity works within their bounds
   - Often constraints force better solutions

### Example: "We need to deploy quarterly"

**Assumed constraint**: "We can't deploy more than quarterly"

**Classification**: Likely self-imposed (unless contractual)

**Challenge**: "Why quarterly? What happens if we deploy monthly?"

**Discover**:
- Process takes 3 months (hard constraint)
- Testing is manual (soft constraint)
- Fear of breaking things (self-imposed)
- Culture says "better safe than sorry" (self-imposed)

**Actual hard constraint**: 3-month process

**Possible interventions**:
- Automate testing (soft → solvable)
- Build confidence (self-imposed → solvable)
- Parallel deployment (design around hard constraint)

**New capability**: Weekly or daily deploys become possible

---

## Assumption Excavation

### The Assumption Iceberg

```
              VISIBLE STRATEGIES
              (What we explicitly plan)
                      ↓
            STATED ASSUMPTIONS
            (What we say we believe)
                      ↓
              TACIT ASSUMPTIONS
              (What we believe unconsciously)
                      ↓
        PARADIGM/WORLDVIEW
        (What we can't even question)
```

### How to Surface Assumptions

**Method 1: Ask "Why?"**
```
Statement: "We can't do X"
Why? "Because Y"
Why Y? "Because Z"
Why Z? "That's just how it is"
→ Found an assumption
```

**Method 2: Look for Consensus**
```
If everyone agrees without debate, there's likely an assumption.
Test it: "What if we didn't believe that?"
Watch reactions: Strong resistance = core assumption
```

**Method 3: Examine Constraints**
```
"We must do X"
Why? Usually an assumption about what's required
Test it: "What if we didn't?"
Learn: Sometimes it's actually negotiable
```

**Method 4: Notice Emotions**
```
When people get emotional, an assumption is threatened
Defensive reaction = core belief
"We can't change that" said angrily = assumption worth examining
```

**Method 5: Historical Investigation**
```
"Why did previous initiatives fail?"
Often reveals assumption that's still operating
"People resist change" → Do they, or did we do something that created resistance?
```

### Common Organizational Assumptions

```
About People:
- "People don't want to work"
- "People resist change"
- "You need to control people to get results"
- "People are primarily motivated by money"

About Work:
- "Work must be unpleasant"
- "More hours = more productivity"
- "Quality and speed are tradeoffs"
- "Innovation requires chaos"

About Change:
- "Change must be imposed from above"
- "People can't be trusted to improve things"
- "We need consultants to fix problems"
- "Change always fails"

About Organization:
- "This is just how our company is"
- "We can't change our culture"
- "Our industry is different"
- "We're too big/small to..."

About Possibility:
- "Technology X isn't possible yet"
- "We can't afford to..."
- "Nobody does that in our sector"
- "That only works for [other type of company]"
```

---

## Knowledge Gap Mapping

### What We Know vs Don't Know

**Category 1: Known Knowns**
- Information we have and are aware we have
- "We know our current productivity is X"

**Category 2: Known Unknowns**
- Information we know we lack
- "We don't know if our customers would accept Y"
- (We know to ask this question)

**Category 3: Unknown Unknowns**
- Information we don't know we lack
- Biggest risk category
- "We never thought to ask Z"

### MARS Approach to Unknowns

**For Known Unknowns**:
- Create research or experiments to fill gaps
- Clear path forward
- Manageable risk

**For Unknown Unknowns**:
- Use systems thinking to predict blindspots
- Ask broadly: "What could we be missing?"
- Test assumptions
- Run pilots to surface surprises
- Expect surprises and plan for them

### Knowledge Gap Audit

```
For this problem, we need to understand:

MUST KNOW (before we proceed):
- [Topic 1]: What we know → What we don't → What we do
- [Topic 2]: ...

SHOULD KNOW (before we're confident):
- [Topic 1]: ...

NICE TO KNOW (but not blocking):
- [Topic 1]: ...

RISKY NOT KNOWING:
- [Topic 1]: ...

What could we be completely blind about?
- [Blindspot 1]: Why we might miss it, how to test
- [Blindspot 2]: ...
```

---

## Paradigm Blindness

### What is a Paradigm?

A shared way of seeing the world that includes:
- What's possible
- What's valuable
- What's real
- How change works
- What problems matter

### Why Paradigms Create Blindness

Within a paradigm:
- Some solutions are invisible (outside the frame)
- Some problems are invisible (not recognized)
- Some evidence is dismissed (doesn't fit the frame)

### Examples

**Paradigm 1: "Manufacturing is about maximizing output"**
```
Visible: Efficiency, speed, volume
Invisible: Worker dignity, learning, innovation
Solutions visible: More machines, faster processes
Solutions invisible: Worker empowerment, continuous improvement culture
```

**Paradigm 2: "Technology solves problems"**
```
Visible: Technical solutions
Invisible: Organizational/people problems
Solutions visible: New systems, automation
Solutions invisible: Culture change, trust building
Problem: Often implements tech into broken system
```

**Paradigm 3: "People resist change"**
```
Visible: Resistance, problems, obstacles
Invisible: Legitimate concerns, valuable expertise
Solutions visible: Stronger leadership, enforcement
Solutions invisible: Genuine engagement, learning
Problem: Self-fulfilling prophecy (coercion creates resistance)
```

### Shifting Paradigms

**Process**:
1. **Name the current paradigm** (what are we assuming?)
2. **Show its limits** (what doesn't it explain?)
3. **Offer alternative** (different way to see this)
4. **Provide evidence** (why might this be true?)
5. **Invite testing** (try it and see)

**Resistance**: Paradigms feel true and natural, so challenging them feels dangerous. Move slowly.

---

## Information Asymmetries

### The Problem
When some people know things others don't:
- Creates power imbalances
- Prevents good decisions
- Enables politics and manipulation
- Blocks genuine collaboration

### Common Asymmetries
```
Management knows financial data, workers don't
→ Workers can't make informed decisions

Engineers know technical constraints, non-tech stakeholders don't
→ Unrealistic demands, missed opportunities

Executives know strategy, staff doesn't
→ Work feels pointless, engagement drops

Customer success team knows what customers want, product doesn't
→ Products don't solve real problems
```

### MARS Approach: Transparency

**Question**: Who needs to know what?

**Strategy**: Make information visible to people who need it
- Real-time dashboards (not restricted reports)
- Honest communication (not spin)
- Context (not just data)
- Why it matters (not just facts)

**Benefit**: Better decisions, more engagement, less politics

---

## Epistemic Analysis Template

```markdown
## PROBLEM: [Description]

## VISIBLE PROBLEMS
- [What everyone sees]
- [What specialists notice]

## HIDDEN PROBLEMS (Systems lens reveals)
- [What only systems view shows]
- [What remains invisible to domain experts]

## INVISIBLE ASSUMPTIONS
Assumption 1: [What we assume about X]
├─ Where it shows up: [How it affects decisions]
├─ Is it true? [Evidence for/against]
└─ What changes if we drop it? [Implications]

Assumption 2: ...

## CONSTRAINT CLASSIFICATION
Hard constraints (immovable):
- [Constraint 1]: [Why hard]

Soft constraints (expensive to move):
- [Constraint 1]: [Cost of moving]

Self-imposed constraints (assumedly hard, but negotiable):
- [Constraint 1]: [Test if movable]

Opportunity: Which soft/self-imposed constraints, if moved, create biggest opportunity?

## KNOWLEDGE GAPS
Must know:
- [Topic]: [What we don't know]

Should know:
- [Topic]: [What we don't know]

Risky not knowing:
- [Topic]: [Why it's risky]

Unknown unknowns (what could we be missing?):
- [Blindspot 1]: [Why it's likely hidden]

## PARADIGM ANALYSIS
Current paradigm: [How we're seeing this]
├─ What's visible: [What this paradigm reveals]
├─ What's invisible: [What it hides]
└─ What needs to shift: [Alternative way of seeing]

## INFORMATION ASYMMETRIES
Who knows what currently?
- [Group 1]: [What they know]
- [Group 2]: [What they know]
- [Missing connection]: [What should be shared]

Impact of asymmetries: [What problems they create]

Transparency needed: [What should be made visible]
```

---

## When MARS Uses Epistemic Dimension

### In Problem Diagnosis
"What are we missing that explains why this isn't working?"

### In Risk Assessment
"What could we be completely blind about?"

### In Assumption Surfacing
"What are we taking for granted that we should test?"

### In Knowledge Gathering
"What do we actually need to understand before proceeding?"

### In Paradigm Work
"What way of seeing this problem would make solutions visible?"

---

## Connection to Other Dimensions

**Epistemic + Structural**:
"We assume this structure is necessary, but what if it isn't?"

**Epistemic + Causal**:
"We think this causes that, but what if the real cause is hidden?"

**Epistemic + Temporal**:
"We think change will be fast, but what are we not seeing about timing?"

**Epistemic + Cultural**:
"We assume people believe X, but what do they actually value?"

**Epistemic + Integrative**:
"Our assumptions are fragmented; what unified view would we have if we examined them?"
